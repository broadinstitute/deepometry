{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (with annotated test set)\n",
    "\n",
    "After training a model to classify single cell images, it is often useful to evaluate the performance of the model on an unseen annotated dataset. Evaluation helps predict model performance on unseen data.\n",
    "\n",
    "Suppose we have the following directory structure. Data from this experiment was not shown to the model during training. Images are saved as NPY files:\n",
    "\n",
    "    /data/parsed/\n",
    "        Experiment 003/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class B/\n",
    "                            B__3618e715e62a229aa78a7e373b49b888.npy\n",
    "                            B__3cf53cea7f4db1cfd101e06c366c9868.npy\n",
    "                            B__84949e1eba7802b00d4a1755fa9af15e.npy\n",
    "                            B__852a1edbf5729fe8721e9e5404a8ad20.npy\n",
    "        ...\n",
    "\n",
    "Use `deepometry.utils.load` to load parsed data and their corresponding labels. We can limit the number of samples to 256 samples per-class by specifying `samples=256`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'D:/Works/non_GSK/Deepometry/Data/APPROACH_Master_EDSRC/STEP1_Parsing/Test'\n",
    "modellocation = 'D:/Works/non_GSK/Deepometry/Data/APPROACH_Master_EDSRC/STEP2_Model_training'\n",
    "output_dir = 'D:/Works/non_GSK/Deepometry/Data/APPROACH_Master_EDSRC/STEP3a_Evaluation/'\n",
    "\n",
    "# Some hyperparameter\n",
    "n_samples = None # sub-sampling for over-representing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-call how many classes there are during the training session. It is crucial to retrieve the list of possible classficiation targets from **the model training session** to ensure the correct reconstruction of categorization, since the training materials should contain all the categories the model has been exposed to. E.g. there could be a situation that one or some categories are missing in a testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_for_model_training = 'D:/Works/non_GSK/Deepometry/Data/APPROACH_Master_EDSRC/STEP1_Parsing/Test'\n",
    "\n",
    "import glob, os, re\n",
    "import itertools\n",
    "all_subdirs = [x[0] for x in os.walk(input_dir_for_model_training)]\n",
    "list1 = sorted(list(set([os.path.basename(i.lower()) for i in all_subdirs[1:]])))\n",
    "keyf = lambda text: re.split('\\s|(?<!\\d)[,._-]|[,._-](?!\\d)', text)[0]\n",
    "sorted([sorted(list(items)) for gr, items in itertools.groupby(list1, key=keyf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy a list from the above output\n",
    "labels_of_interest = [\n",
    "    'class_crenateddisc_',\n",
    "    'class_crenateddiscoid',\n",
    "    'class_crenatedsphere',\n",
    "    'class_crenatedspheroid',\n",
    "    'class_side',\n",
    "    'class_smoothdisc',\n",
    "    'class_smoothsphere'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "# configuration.gpu_options.visible_device_list = \"0\"\n",
    "session = tensorflow.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathnames_of_interest = deepometry.utils.collect_pathnames(input_dir, labels_of_interest, n_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _ = deepometry.utils._load(pathnames_of_interest, labels_of_interest)\n",
    "\n",
    "units = len(list(set(labels_of_interest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation and target data (`x` and `y`, respectively) is next passed to the model for evaluation. **A previously trained model is required.** The `evaluate` method loads the trained model weights. See the `fit` notebook for instructions on training a model. \n",
    "\n",
    "Evaluation data is provided to the model in batches of 32 samples. Use `batch_size` to configure the number of samples. A smaller `batch_size` requires less memory.\n",
    "\n",
    "The evaluate function outputs the model's loss and accuracy metrics as the array `[loss, accuracy]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=units)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "predicted = model.predict(x, modellocation, batch_size=32, verbose=1)\n",
    "\n",
    "predicted = numpy.argmax(predicted, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y\n",
    "\n",
    "confusion = sklearn.metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "# Normalize values in confusion matrix\n",
    "confusion = confusion.astype('float') / confusion.sum(axis=1)[:, numpy.newaxis]\n",
    "confusion = pandas.DataFrame(confusion)\n",
    "confusion = confusion.rename(index={index: label for index, label in enumerate(labels_of_interest)}, columns={index: label for index, label in enumerate(labels_of_interest)})\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, _ = plt.subplots()\n",
    "fig.set_size_inches(10, 10) \n",
    "plt.imshow(confusion, interpolation='nearest', cmap=plt.cm.Blues )\n",
    "plt.colorbar()\n",
    "plt.xticks(numpy.arange(len(labels_of_interest)), labels_of_interest, rotation=45)\n",
    "plt.yticks(numpy.arange(len(labels_of_interest)), labels_of_interest)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = confusion.max() / 2.\n",
    "for i, j in itertools.product(range(confusion.shape[0]), range(confusion.shape[1])):\n",
    "    plt.text(j, i, format(confusion.iloc[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if numpy.all(confusion.iloc[i, j] > thresh) else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pandas.DataFrame(sklearn.metrics.classification_report(expected, predicted, output_dict=True)).transpose()\n",
    "report.index = labels_of_interest + ['accuracy', 'macro avg', 'weighted avg']\n",
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
