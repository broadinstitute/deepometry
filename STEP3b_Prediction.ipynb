{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction (with unannotated test set)\n",
    "\n",
    "After training, the model can be used as a classifier on an unknown/unannotated dataset.\n",
    "\n",
    "Suppose we have the following directory structure. Data from this experiment was not shown to the model during training. Images are saved as NPY files:\n",
    "\n",
    "    /data/parsed/\n",
    "        Experiment 003/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Unknown class/\n",
    "                            B__3618e715e62a229aa78a7e373b49b888.npy\n",
    "                            B__3cf53cea7f4db1cfd101e06c366c9868.npy\n",
    "                            B__84949e1eba7802b00d4a1755fa9af15e.npy\n",
    "                            B__852a1edbf5729fe8721e9e5404a8ad20.npy\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Data/STEP1_Preprocessing'\n",
    "modellocation = 'Data/STEP2_Model_training'\n",
    "output_dir = '/Data/STEP3_Evaluation'\n",
    "\n",
    "# Some hyperparameter\n",
    "n_samples = None # sub-sampling for over-representing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-call how many classes there are during the training session. It is crucial to retrieve the list of possible classficiation targets from **the model training session** to ensure the correct reconstruction of categorization, since the training materials should contain all the categories the model has been exposed to. E.g. there could be a situation that one or some categories are missing in a testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir_for_model_training = '/Data/STEP1_Preprocessing'\n",
    "\n",
    "import glob, os, re\n",
    "from itertools import groupby\n",
    "all_subdirs = [x[0] for x in os.walk(input_dir_for_model_training)]\n",
    "list1 = sorted(list(set([os.path.basename(i.lower()) for i in all_subdirs[1:]])))\n",
    "keyf = lambda text: re.split('\\s|(?<!\\d)[,._-]|[,._-](?!\\d)', text)[0]\n",
    "sorted([sorted(list(items)) for gr, items in groupby(list1, key=keyf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy a list from the above output\n",
    "labels_of_interest = ['class_crenateddisc_', 'class_crenateddiscoid', 'class_crenatedsphere', 'class_crenatedspheroid', 'class_side', 'class_smoothdisc', 'class_smoothsphere']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "# configuration.gpu_options.visible_device_list = \"0\"\n",
    "session = tensorflow.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathnames_of_interest = deepometry.utils.collect_pathnames(input_dir, labels_of_interest, n_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _, _ = deepometry.utils._load(pathnames_of_interest, labels_of_interest)\n",
    "\n",
    "units = len(list(set(labels_of_interest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=units)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "predicted = model.predict(x, modellocation, batch_size=32, verbose=1)\n",
    "\n",
    "predicted = numpy.argmax(predicted, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = pandas.DataFrame()\n",
    "predicted_classes['numeric_class'] = predicted\n",
    "predicted_classes['label'] = [labels_of_interest[i] for i in predicted]\n",
    "predicted_classes.to_csv(os.path.join(output_dir,'predicted.csv'), index=True, index_label='ID')\n",
    "\n",
    "# Simple count plot:\n",
    "plt.figure(figsize = (9, 6))\n",
    "seaborn.countplot(x=\"label\", data=predicted_classes)\n",
    "plt.xticks(rotation=60)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
