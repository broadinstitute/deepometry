{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "Suppose we have the following directory structure. Data from this experiment was shown to the model during training. Images are saved as NPY files:\n",
    "\n",
    "    /data/parsed/\n",
    "        Experiment 001/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class A/\n",
    "                            A__32e88e1ac3a8f44bf8f77371155553b9.npy\n",
    "                            A__3dc56a0c446942aa0da170acfa922091.npy\n",
    "                        Class B/\n",
    "                            B__8068ef7dcddd89da4ca9740bd2ccb31e.npy\n",
    "        Experiment 002/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class A/\n",
    "                            A__8348deaa70dfc95c46bd02984d28b873.npy\n",
    "                        Class B/\n",
    "                            B__c1ecbca7bd98c01c1d3293b64cd6739a.npy\n",
    "                            B__c56cfb8e7e7121dd822e47c67d07e2d4.npy\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Data/STEP1_Parsing/'\n",
    "modellocation = '/Data/STEP2_Model_training/'\n",
    "output_dir = '/Data/STEP3c_Extraction/'\n",
    "feature_extraction_layer = 'res5a_relu'\n",
    "frame = 48 # frame size of each single-cell image\n",
    "\n",
    "# Some hyperparameter\n",
    "n_samples = None # sub-sampling for over-representing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, glob, re\n",
    "import matplotlib.pyplot\n",
    "import pandas\n",
    "import skimage.io\n",
    "import numpy\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils\n",
    "import deepometry.visualize\n",
    "\n",
    "import keras.backend\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata(file, metadata_bkpr, metadata_depth):\n",
    "\n",
    "    meta = [re.split('\\s|(?<!\\d)[,._-]|[,._-](?!\\d)', i)[0] for i in metadata_depth]\n",
    "\n",
    "    with open(file, 'w') as f:\n",
    "        f.write( meta[0] + '\\t' + meta[1] + '\\t' + meta[2] + '\\t' + meta[3] + '\\t' + meta[4] + '\\n')\n",
    "        for i in range(len(metadata_bkpr)):\n",
    "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format( metadata_bkpr[i][0], metadata_bkpr[i][1], metadata_bkpr[i][2], metadata_bkpr[i][3], metadata_bkpr[i][4]))\n",
    "            \n",
    "            \n",
    "def split_all(path):\n",
    "    \"\"\"\n",
    "    Break a path into unit components\n",
    "    \"\"\"\n",
    "\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "# configuration.gpu_options.visible_device_list = \"0\"\n",
    "\n",
    "session = tensorflow.Session(config=configuration)\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathnames_of_interest = [j for i in [x[0] for x in os.walk(input_dir)] for j in glob.glob(os.path.join(i,'*')) if '.npy' in j]\n",
    "\n",
    "x, _, metadata_bkpr = deepometry.utils._load(pathnames_of_interest)\n",
    "\n",
    "if os.path.isdir(modellocation):\n",
    "    list_of_files = glob.glob(os.path.join(modellocation, '*_categories.h5')) # only file with correct naming, i.e.***_categories.h5, is accepted\n",
    "    modellocation = max(list_of_files, key=os.path.getctime)    \n",
    "units = int( re.search('model_([0-9]*)-.*_categories.h5', os.path.basename(modellocation)).group(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=units)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "# Extract the features\n",
    "features = model.extract(x, feature_extraction_layer, trained_model_location, batch_size=32, standardize=True, verbose=1)\n",
    "\n",
    "if len(features.shape) > 2:\n",
    "    a = numpy.mean(features, axis = 1)\n",
    "    del(features)\n",
    "    features = numpy.mean(a, axis = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is loaded, we can redefine the model and extract the embedded features of `x`. The features will be saved as a TSV file using pandas. We omit the column headers and the data frame indexes from the exported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)   \n",
    "\n",
    "# Export features to .TXT file, to be used on http://projector.tensorflow.org\n",
    "numpy.savetxt( os.path.join(output_dir, 'features_extracted_by_'+ feature_extraction_layer +'.txt'), features, delimiter='\\t')\n",
    "\n",
    "# Export features to .TSV file, to be used in local Tensorboard\n",
    "features_df = pandas.DataFrame(data=features)\n",
    "features_df.to_csv( os.path.join(output_dir, 'features_extracted_by_'+ feature_extraction_layer +'.tsv'), header=False, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional metadata can also be exported as a TSV. In this example, we export a single-column TSV containing the label data. Single-column metadata should exclude the column header (`header=False`). Metadata containing more than one column should include the column header (`header=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save labels, to be used as \"metadata\" on http://projector.tensorflow.org\n",
    "save_metadata(os.path.join(output_dir, 'metadata.tsv'), metadata_bkpr, metadata_depth=split_all(pathnames_of_interest[0])[-6:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "Visualize an embedded feature spacing using TensorBoard or on the web-app http://projector.tensorflow.org. Use the outputs from `extract` to populate the features, metadata, and sprites parameters for `deepometry.visualize.make_projection`.\n",
    "\n",
    "When using TensorBoard to visualize an embedding, you can display a \"sprite\" image for each data point. The sprite image is an NxN grid of image data. Use `deepometry.visualize.images_to_sprites` to create this grid. The `sprites_dim` parameter tells TensorBoard how big (in pixels) each sprite is. For example, if a single sprit is 48x48 pixels, then `sprites_dim=48`.\n",
    "\n",
    "To launch TensorBoard, copy the output of the cell below and run it in your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sprites image.\n",
    "sprites = deepometry.visualize.images_to_sprite(x)\n",
    "\n",
    "# Export the sprites image.\n",
    "skimage.io.imsave(os.path.join(output_dir,'sprites.png'), sprites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = os.path.abspath(glob.glob(os.path.join(output_dir,'*feature*.tsv'))[0])\n",
    "metadata_file = os.path.abspath(os.path.join(output_dir,'metadata.tsv'))\n",
    "sprites_file = os.path.abspath(os.path.join(output_dir,'sprites.png'))\n",
    "sprites_dim = frame\n",
    "\n",
    "log_directory = deepometry.visualize.make_projection(\n",
    "    features_file,\n",
    "    metadata=metadata_file,\n",
    "    sprites=sprites_file,\n",
    "    sprites_dim=frame\n",
    ")\n",
    "\n",
    "# Copy and execute this command on the terminal\n",
    "print(\"tensorboard --logdir {:s}\".format(log_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
