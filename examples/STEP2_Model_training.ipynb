{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "After parsing raw image data, we expectingly have the following directory structure, where data arrays as .NPYs are saved in subdirectories named after the class labels (e.g. `Class Positive`, `Class Negative` etc.).\n",
    "\n",
    "    /data/parsed/\n",
    "        Experiment 001/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class A/\n",
    "                            A__32e88e1ac3a8f44bf8f77371155553b9.npy\n",
    "                            A__3dc56a0c446942aa0da170acfa922091.npy\n",
    "                        Class B/\n",
    "                            B__8068ef7dcddd89da4ca9740bd2ccb31e.npy\n",
    "        Experiment 002/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class A/\n",
    "                            A__8348deaa70dfc95c46bd02984d28b873.npy\n",
    "                        Class B/\n",
    "                            B__c1ecbca7bd98c01c1d3293b64cd6739a.npy\n",
    "                            B__c56cfb8e7e7121dd822e47c67d07e2d4.npy\n",
    "\n",
    "        ...\n",
    "                \n",
    "The data can be used to train a model to classify image data as one of each class. The `deepometry.utils.load` function selects images to use for training the model and generate the labels for the training images.\n",
    "\n",
    "Suppose there is a large imbalance between the number of samples per class in each experiment. Undersampling across classes balances the data seen by the model during training. Additionally, `class_weights` are introduced to work together with undersampling to improve prediction accuracy in underrepresented classes. The `deepometry.utils.load` function performs undersampling across classes (per-experiment) with `sample=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Data/STEP1_Parsing'\n",
    "output_dir = '/Data/STEP2_Trained_model'\n",
    "class_option = 'class'\n",
    "\n",
    "# Some hyperparameter\n",
    "n_samples = None # sub-sampling for over-representing classes\n",
    "validation_split=0.2\n",
    "batch_size=32\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import pkg_resources\n",
    "import tensorflow\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "# configuration.gpu_options.visible_device_list = \"0\"\n",
    "session = tensorflow.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subdirs = [x[0] for x in os.walk(input_dir)]\n",
    "possible_labels = sorted(list(set([os.path.basename(i) for i in all_subdirs])))\n",
    "labels_of_interest = [i for i in possible_labels if class_option.lower() in i.lower()]\n",
    "\n",
    "pathnames_of_interest = deepometry.utils.collect_pathnames(input_dir, labels_of_interest, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _ = deepometry.utils._load(pathnames_of_interest, labels_of_interest)\n",
    "\n",
    "units = len(list(set(labels_of_interest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and target data (`x` and `y`, respectively) is next passed to the model for training. The model is confiured to withhold 20% of the training data for validation. Use `validation_split` to adjust the size of the partition.\n",
    "\n",
    "The model will iterate over the training data at most 512 times, specified by `epochs`. Training will terminate early if the validation loss fails to improve for 20 epochs. Training and validation data is provided to the model in batches of 32 samples. Use `batch_size` to configure the number of samples. A smaller `batch_size` requires less memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=units)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "print('Model training... Please wait!')\n",
    "\n",
    "model.fit(\n",
    "    x,\n",
    "    y,\n",
    "    balance_train=False,\n",
    "    class_weight=None,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pandas.read_csv(pkg_resources.resource_filename(\"deepometry\", \"data/training.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax0, ax1) = matplotlib.pyplot.subplots(ncols=2, figsize=(16, 4))\n",
    "\n",
    "ax0.plot(csv[\"acc\"], c=\"r\")\n",
    "ax0.plot(csv[\"val_acc\"], c=\"b\")\n",
    "\n",
    "ax1.plot(csv[\"loss\"][0:], c=\"r\")\n",
    "ax1.plot(csv[\"val_loss\"][0:], c=\"b\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
