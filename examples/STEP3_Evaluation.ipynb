{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "After training a model to classify single cell images, it is often useful to evaluate the performance of the model on an unseen annotated dataset. Evaluation helps predict model performance on unseen data.\n",
    "\n",
    "Suppose we have the following directory structure. Data from this experiment was not shown to the model during training. Images are saved as NPY files with patient prefixes:\n",
    "\n",
    "    /data/parsed/\n",
    "        Experiment 003/\n",
    "            Day 1/\n",
    "                Sample A/\n",
    "                    Replicate 1/\n",
    "                        Class B/\n",
    "                            B__3618e715e62a229aa78a7e373b49b888.npy\n",
    "                            B__3cf53cea7f4db1cfd101e06c366c9868.npy\n",
    "                            B__84949e1eba7802b00d4a1755fa9af15e.npy\n",
    "                            B__852a1edbf5729fe8721e9e5404a8ad20.npy\n",
    "        ...\n",
    "\n",
    "**User should reload data structure as used during model training**, then use `deepometry.utils.load` to load parsed data and their corresponding labels. We can limit the number of samples to 256 samples per-class by specifying `samples=256`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/Data/STEP1_Parsing'\n",
    "output_dir = '/Data/STEP3_Evaluation'\n",
    "class_option = 'class'\n",
    "\n",
    "# Re-call how many classes there are during the training session\n",
    "input_dir_for_model_training = '/Data/STEP1_Parsing'\n",
    "\n",
    "# Some hyperparameter\n",
    "n_samples = None # sub-sampling for over-representing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "# configuration.gpu_options.visible_device_list = \"0\"\n",
    "session = tensorflow.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subdirs = [x[0] for x in os.walk(input_dir_for_model_training)]\n",
    "possible_labels = sorted(list(set([os.path.basename(i) for i in all_subdirs])))\n",
    "labels_of_interest = [i for i in possible_labels if class_option.lower() in i.lower()]\n",
    "\n",
    "pathnames_of_interest = deepometry.utils.collect_pathnames(input_dir, labels_of_interest, n_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, _ = deepometry.utils._load(pathnames_of_interest, labels_of_interest)\n",
    "\n",
    "units = len(list(set(labels_of_interest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation and target data (`x` and `y`, respectively) is next passed to the model for evaluation. **A previously trained model is required.** The `evaluate` method loads the trained model weights. See the `fit` notebook for instructions on training a model. \n",
    "\n",
    "Evaluation data is provided to the model in batches of 32 samples. Use `batch_size` to configure the number of samples. A smaller `batch_size` requires less memory.\n",
    "\n",
    "The evaluate function outputs the model's loss and accuracy metrics as the array `[loss, accuracy]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=units)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "predicted = model.predict(x, output_dir, batch_size=32)\n",
    "\n",
    "predicted = numpy.argmax(predicted, -1)\n",
    "expected = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "# Normalize values in confusion matrix\n",
    "confusion = confusion.astype('float') / confusion.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "confusion = pandas.DataFrame(confusion)\n",
    "confusion = confusion.rename(index={index: label for index, label in enumerate(labels_of_interest)}, columns={index: label for index, label in enumerate(labels_of_interest)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "seaborn.heatmap(confusion, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(expected, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
