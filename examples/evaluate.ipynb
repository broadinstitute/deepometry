{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot\n",
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import tensorflow\n",
    "\n",
    "import deepometry.model\n",
    "import deepometry.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "After training a model to classify single cell images, it is often useful to evaluate the performance of the model on an unseen annotated dataset. Evaluation helps predict model performance on unseen data.\n",
    "\n",
    "Suppose we have the following directory structure. Data from this experiment was not shown to the model during training. Images are saved as NPY files with patient prefixes:\n",
    "\n",
    "    /data/parsed/\n",
    "        patient_C/\n",
    "            positive/\n",
    "                patient_C__32e88e1ac3a8f44bf8f77371155553b9.npy\n",
    "                patient_C__3dc56a0c446942aa0da170acfa922091.npy  \n",
    "                ...\n",
    "            negative/\n",
    "                patient_C__8068ef7dcddd89da4ca9740bd2ccb31e.npy\n",
    "                patient_C__8348deaa70dfc95c46bd02984d28b873.npy\n",
    "                ...\n",
    "                \n",
    "\n",
    "The data can be used to evaluate a model for classifying image data as one of the three classes. The `deepometry.utils.load` function selects images to use for evaluating the model and generate the labels for the evaluation images. We can limit the number of samples to 256 samples per-class by specifying `samples=256`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x, y, units = deepometry.utils.load([\"data/parsed/patient_C\"], sample=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tensorflow.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"3\"\n",
    "session = tensorflow.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classification test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The evaluation and target data (`x` and `y`, respectively) is next passed to the model for evaluation. **A previously trained model is required.** The `evaluate` method loads the trained model weights. See the `fit` notebook for instructions on training a model. \n",
    "\n",
    "Evaluation data is provided to the model in batches of 32 samples. Use `batch_size` to configure the number of samples. A smaller `batch_size` requires less memory.\n",
    "\n",
    "The evaluate function outputs the model's loss and accuracy metrics as the array `[loss, accuracy]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = deepometry.model.Model(shape=x.shape[1:], units=4)\n",
    "\n",
    "model.compile()\n",
    "\n",
    "predicted = model.predict(\n",
    "    batch_size=50,\n",
    "    x=x\n",
    ")\n",
    "\n",
    "predicted = numpy.argmax(predicted, -1)\n",
    "expected = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "confusion = pandas.DataFrame(confusion)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "seaborn.heatmap(confusion, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "confusion = confusion.astype('float') / confusion.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "confusion = pandas.DataFrame(confusion)\n",
    "\n",
    "matplotlib.pyplot.figure(figsize=(12, 8))\n",
    "\n",
    "seaborn.heatmap(confusion, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.accuracy_score(expected, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
